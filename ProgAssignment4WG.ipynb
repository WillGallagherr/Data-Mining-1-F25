{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T06:42:29.036808Z",
     "start_time": "2025-12-15T06:42:29.030950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##Cell imported from given link:https://www.kozodoi.me/blog/extracting-intermediate-layer-outputs-in-pytorch\n",
    "##### PACKAGES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import timm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "##### DATASET\n",
    "\n",
    "\n",
    "class ImageData(Dataset):\n",
    "    # init\n",
    "    def __init__(self, data, directory, transform):\n",
    "        self.data = data\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "\n",
    "    # length\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # get item\n",
    "    def __getitem__(self, idx):\n",
    "        # import\n",
    "        image = cv2.imread(\n",
    "            os.path.join(self.directory, self.data.iloc[idx][\"image_id\"])\n",
    "        )\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # augmentations\n",
    "        image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        return image\n",
    "    \n",
    "    \n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T06:42:32.182191Z",
     "start_time": "2025-12-15T06:42:32.155712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##Cell imported from given link and modified:https://www.kozodoi.me/blog/extracting-intermediate-layer-outputs-in-pytorch \n",
    "##### DATA LOADER\n",
    "\n",
    "# augmentations\n",
    "#transforms = A.Compose([A.Resize(height=224, width=224), A.Normalize(), ToTensorV2()])\n",
    "\n",
    "#feature extraction loop gave errors from Albumentations aug so I am trying standard pytorch transforms as I am much more familliar with it\n",
    "from torchvision import datasets, transforms\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "\n",
    "# dataset\n",
    "#change from original version, using ImageFolder to use data label pair from current file system insead of having a dataframe (https://docs.pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html)\n",
    "\n",
    "data_set = datasets.ImageFolder(\n",
    "    root=\"data\",\n",
    "    transform=transforms,\n",
    ")\n",
    "\n",
    "# dataloader\n",
    "data_loader = DataLoader(data_set, batch_size=32, shuffle=False, num_workers=2)"
   ],
   "id": "d509c68a7e8d7e66",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T06:42:35.420679Z",
     "start_time": "2025-12-15T06:42:34.849403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##Cell imported from given link:https://www.kozodoi.me/blog/extracting-intermediate-layer-outputs-in-pytorch\n",
    "##### DEFINE MODEL\n",
    "\n",
    "model = timm.create_model(model_name=\"resnet18\", pretrained=True)\n",
    "model.fc = nn.Linear(512, 2)\n",
    "model.to(device)"
   ],
   "id": "91723c83b6f146a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T06:42:51.525910Z",
     "start_time": "2025-12-15T06:42:37.455301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##Cell imported from given link and modified:https://www.kozodoi.me/blog/extracting-intermediate-layer-outputs-in-pytorch \n",
    "##### HELPER FUNCTION FOR FEATURE EXTRACTION\n",
    "\n",
    "\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "\n",
    "    return hook\n",
    "\n",
    "##### REGISTER HOOK\n",
    "#another slight change, want last conv layer only so directly accessing through layer4 might do it\n",
    "#also switched hook referencing from global_pool to layer4\n",
    "model.layer4.register_forward_hook(get_features(\"layer4\"))\n",
    "\n",
    "##### FEATURE EXTRACTION LOOP\n",
    "\n",
    "# placeholders\n",
    "PREDS = []\n",
    "FEATS = []\n",
    "lables = []\n",
    "\n",
    "# placeholder for batch features\n",
    "#features = {\"{\"\"}\"}\n",
    "features = {}\n",
    "\n",
    "# loop through batches\n",
    "model.eval()\n",
    "#needed to extend input to a tuple based on the return of how imagefolder is enumerated:https://docs.pytorch.org/vision/main/_modules/torchvision/datasets/folder.html#DatasetFolder\n",
    "for idx, (inputs, y) in enumerate(data_loader):\n",
    "    # move to device\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    # forward pass [with feature extraction]\n",
    "    preds = model(inputs)\n",
    "\n",
    "    # add feats and preds to lists\n",
    "    PREDS.append(preds.detach().cpu().numpy())\n",
    "    FEATS.append(features[\"layer4\"].cpu().numpy())\n",
    "    lables.append(y.numpy())\n",
    "    \n",
    "\n",
    "    # early stop\n",
    "    #getting rid of this to see if it will take too long to do everything\n",
    "    #if idx == 9:\n",
    "    #    break\n",
    "        \n",
    "##### INSPECT FEATURES\n",
    "\n",
    "PREDS = np.concatenate(PREDS)\n",
    "FEATS = np.concatenate(FEATS)\n",
    "lables = np.concatenate(lables)\n",
    "\n",
    "print(\"- preds shape:\", PREDS.shape)\n",
    "print(\"- feats shape:\", FEATS.shape)"
   ],
   "id": "2e90eab61d33292b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- preds shape: (5631, 2)\n",
      "- feats shape: (5631, 512, 7, 7)\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T06:42:53.156500Z",
     "start_time": "2025-12-15T06:42:53.065070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#converting features to 2d matrix to make it closer to assignment 1 enviornment\n",
    "FEATS = FEATS.mean(axis=(2, 3))\n",
    "pca = PCA(n_components=2).fit_transform(FEATS)"
   ],
   "id": "2e8a0b1972554e56",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T06:50:49.501508Z",
     "start_time": "2025-12-15T06:50:44.581901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, BisectingKMeans, SpectralClustering, DBSCAN, AgglomerativeClustering\n",
    "x = StandardScaler().fit_transform(pca)\n",
    "\n",
    "kmean = KMeans(n_clusters=4, init=\"random\", random_state=0).fit_predict(x)\n",
    "\n",
    "kmeanplus = KMeans(n_clusters=4, init=\"k-means++\", random_state=0).fit_predict(x)\n",
    "\n",
    "bisect_kmean = BisectingKMeans(n_clusters=4, init=\"random\", random_state=0).fit_predict(x)\n",
    "\n",
    "spectral = SpectralClustering(n_clusters=4).fit_predict(x)\n",
    "\n",
    "bdbs = DBSCAN(eps=0.15, min_samples=10).fit_predict(x) #4 clusters found at 0.15, 10\n",
    "labs = set(bdbs) #remove dupes\n",
    "k = len(labs) - 1 #-1 are noise points\n",
    "print(k)\n",
    "\n",
    "s_link = AgglomerativeClustering(n_clusters=4, linkage=\"single\").fit_predict(x)\n",
    "\n",
    "c_link = AgglomerativeClustering(n_clusters=4, linkage=\"complete\").fit_predict(x)\n",
    "\n",
    "avg = AgglomerativeClustering(n_clusters=4, linkage=\"average\").fit_predict(x)\n",
    "\n",
    "ward = AgglomerativeClustering(n_clusters=4, linkage=\"ward\").fit_predict(x)\n"
   ],
   "id": "3dd9174afacd0aaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4 clusters found at eps = 0.15 and min_samples = 10",
   "id": "365795257ab2952e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T07:07:32.232035Z",
     "start_time": "2025-12-15T07:07:29.883967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import fowlkes_mallows_score, silhouette_score\n",
    "\n",
    "#cluster eval\n",
    "clusters = {\n",
    "    \"KMeans_r\": kmean,\n",
    "    \"KMeans_plus\": kmeanplus,\n",
    "    \"BisectKMeans\": bisect_kmean,\n",
    "    \"Spectral\": spectral,\n",
    "    \"DBSCAN\": bdbs,\n",
    "    \"ag_link\": s_link,\n",
    "    \"ag_link\": c_link,\n",
    "    \"ag_link\": avg,\n",
    "    \"ag_ward\": ward,\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, perf in clusters.items():\n",
    "    perf = np.asarray(perf)\n",
    "    fowlkes_mallows = fowlkes_mallows_score(lables, perf)\n",
    "\n",
    "    silhouette = silhouette_score(x, perf)\n",
    "\n",
    "    results.append({\"name\": name, \"fowlkes_mallows\": fowlkes_mallows, \"silhouette\": silhouette})\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "print(results)"
   ],
   "id": "d4f3c256211bba1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name  fowlkes_mallows  silhouette\n",
      "0      KMeans_r         0.555400    0.521975\n",
      "1   KMeans_plus         0.489216    0.379858\n",
      "2  BisectKMeans         0.560382    0.521178\n",
      "3      Spectral         0.562499    0.472963\n",
      "4        DBSCAN         0.489946    0.230978\n",
      "5       ag_link         0.543338    0.511228\n",
      "6       ag_ward         0.555194    0.501841\n"
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T06:59:07.939341Z",
     "start_time": "2025-12-15T06:59:07.932217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#ranking\n",
    "print(\"Fowlkes-Mallows Ranking\")\n",
    "rank_fowlkes_mallows = results.sort_values(\"fowlkes_mallows\", ascending=False)\n",
    "print(rank_fowlkes_mallows)\n",
    "print(\"silhouette ranking\")\n",
    "rank_silhouette = results.sort_values(\"silhouette\", ascending=False)\n",
    "print(rank_silhouette)"
   ],
   "id": "d0121181d45e197b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fowlkes-Mallows Ranking\n",
      "           name  fowlkes_mallows  silhouette\n",
      "3      Spectral         0.562499    0.472963\n",
      "2  BisectKMeans         0.560382    0.521178\n",
      "0      KMeans_r         0.555400    0.521975\n",
      "6       ag_ward         0.555194    0.501841\n",
      "5       ag_link         0.543338    0.511228\n",
      "4        DBSCAN         0.489946    0.230978\n",
      "1   KMeans_plus         0.489216    0.379858\n",
      "silhouette ranking\n",
      "           name  fowlkes_mallows  silhouette\n",
      "0      KMeans_r         0.555400    0.521975\n",
      "2  BisectKMeans         0.560382    0.521178\n",
      "5       ag_link         0.543338    0.511228\n",
      "6       ag_ward         0.555194    0.501841\n",
      "3      Spectral         0.562499    0.472963\n",
      "1   KMeans_plus         0.489216    0.379858\n",
      "4        DBSCAN         0.489946    0.230978\n"
     ]
    }
   ],
   "execution_count": 119
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
